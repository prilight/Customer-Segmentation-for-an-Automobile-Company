{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3de02ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95ac608d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training and test datasets\n",
    "train_df = pd.read_csv('Train.csv')\n",
    "test_df = pd.read_csv('Test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa018295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target in the training data\n",
    "X_train = train_df.drop('Segmentation', axis=1)\n",
    "y_train = train_df['Segmentation']\n",
    "\n",
    "# Ensure the test data has the same features\n",
    "X_test = test_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f1c2b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns inspection:\n",
      "Age:\n",
      "[22 38 67 40 56 32 33 61 55 26 19 70 58 41 31 79 49 18 36 35 45 42 83 27\n",
      " 28 47 29 57 76 25 72 48 74 59 39 51 30 63 52 60 68 86 50 43 80 37 46 69\n",
      " 78 71 82 23 20 85 21 53 62 75 65 89 66 73 77 87 84 81 88]\n",
      "Work_Experience:\n",
      "[ 1. nan  0.  4.  9. 12.  3. 13.  5.  8. 14.  7.  2.  6. 10. 11.]\n",
      "Spending_Score:\n",
      "['Low' 'Average' 'High']\n",
      "Family_Size:\n",
      "[ 4.  3.  1.  2.  6. nan  5.  8.  7.  9.]\n"
     ]
    }
   ],
   "source": [
    "# List of numerical and categorical columns\n",
    "numerical_features = ['Age', 'Work_Experience', 'Spending_Score', 'Family_Size']\n",
    "categorical_features = ['Gender', 'Ever_Married', 'Graduated', 'Profession', 'Var_1']\n",
    "\n",
    "# Inspect numerical columns\n",
    "print(\"Numerical columns inspection:\")\n",
    "for col in numerical_features:\n",
    "    print(f\"{col}:\")\n",
    "    print(X_train[col].unique())\n",
    "\n",
    "# Handle non-numeric values in numerical columns if necessary\n",
    "# For example, converting 'Low', 'Medium', 'High' to numerical values\n",
    "X_train['Spending_Score'] = X_train['Spending_Score'].replace({'Low': 1, 'Medium': 2, 'Average': 3, 'High': 4})\n",
    "X_test['Spending_Score'] = X_test['Spending_Score'].replace({'Low': 1, 'Medium': 2, 'Average': 3, 'High': 4})\n",
    "\n",
    "# Preprocessing for numerical data: impute missing values and scale\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Preprocessing for categorical data: impute missing values and one-hot encode\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Combine preprocessing steps\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "929aa205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.48079306071871125\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           A       0.36      0.36      0.36       391\n",
      "           B       0.37      0.35      0.36       369\n",
      "           C       0.50      0.51      0.50       380\n",
      "           D       0.64      0.66      0.65       474\n",
      "\n",
      "    accuracy                           0.48      1614\n",
      "   macro avg       0.47      0.47      0.47      1614\n",
      "weighted avg       0.48      0.48      0.48      1614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating a pipeline that includes preprocessing and the classifier\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Spliting training data for validation\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Validating the model\n",
    "y_val_pred = model.predict(X_val_split)\n",
    "print(\"Validation Accuracy: \", accuracy_score(y_val_split, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_split, y_val_pred))\n",
    "\n",
    "# Predicting the segments for the test data\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Creating a DataFrame with predictions\n",
    "test_predictions = pd.DataFrame({'Customer_ID': test_df['ID'], 'Predicted_Segment': y_test_pred})\n",
    "\n",
    "# Saving predictions to a CSV file\n",
    "test_predictions.to_csv('test_predictions.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15eacd20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy:  0.5297397769516728\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           A       0.44      0.43      0.43       391\n",
      "           B       0.42      0.33      0.37       369\n",
      "           C       0.52      0.57      0.54       380\n",
      "           D       0.66      0.74      0.70       474\n",
      "\n",
      "    accuracy                           0.53      1614\n",
      "   macro avg       0.51      0.52      0.51      1614\n",
      "weighted avg       0.52      0.53      0.52      1614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "# Defining the parameter grid for Grid Search\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Creating a GridSearchCV object\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "# Training the model using Grid Search\n",
    "grid_search.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Getting the best model from Grid Search\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Validating the best model\n",
    "y_val_pred = best_model.predict(X_val_split)\n",
    "print(\"Validation Accuracy: \", accuracy_score(y_val_split, y_val_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_val_split, y_val_pred))\n",
    "\n",
    "# Predicting the segments for the test data using the best model\n",
    "y_test_pred = best_model.predict(X_test)\n",
    "\n",
    "# Creating a DataFrame with predictions\n",
    "test_predictions = pd.DataFrame({'Customer_ID': test_df['ID'], 'Predicted_Segment': y_test_pred})\n",
    "\n",
    "# Saving predictions to a CSV file\n",
    "test_predictions.to_csv('test_prediction.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "30b9b6c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'classifier__max_depth': 10, 'classifier__min_samples_leaf': 1, 'classifier__min_samples_split': 10, 'classifier__n_estimators': 300}\n",
      "Best accuracy:  0.5409027314923232\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Defining the parameter grid\n",
    "param_grid = {\n",
    "    'classifier__n_estimators': [100, 200, 300],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Creating the GridSearchCV object\n",
    "grid_search = GridSearchCV(model, param_grid, cv=5, n_jobs=-1, scoring='accuracy')\n",
    "\n",
    "# Fitting the model\n",
    "grid_search.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Printing the best parameters and best score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best accuracy: \", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "280a87b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned RandomForestClassifier Validation Accuracy:  0.5322180916976456\n",
      "Tuned RandomForestClassifier Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           A       0.45      0.44      0.45       391\n",
      "           B       0.43      0.33      0.37       369\n",
      "           C       0.52      0.57      0.54       380\n",
      "           D       0.65      0.74      0.69       474\n",
      "\n",
      "    accuracy                           0.53      1614\n",
      "   macro avg       0.51      0.52      0.51      1614\n",
      "weighted avg       0.52      0.53      0.52      1614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Defining the RandomForestClassifier with the best parameters\n",
    "best_rf = RandomForestClassifier(\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=10,\n",
    "    n_estimators=300,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Creating a pipeline with the best RandomForestClassifier\n",
    "best_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', best_rf)\n",
    "])\n",
    "\n",
    "# Training the model on the training data\n",
    "best_model.fit(X_train_split, y_train_split)\n",
    "\n",
    "# Predicting on the validation data\n",
    "y_val_pred_best = best_model.predict(X_val_split)\n",
    "\n",
    "# Evaluating the model's performance\n",
    "print(\"Tuned RandomForestClassifier Validation Accuracy: \", accuracy_score(y_val_split, y_val_pred_best))\n",
    "print(\"Tuned RandomForestClassifier Classification Report:\\n\", classification_report(y_val_split, y_val_pred_best))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866c5a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "060c3bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TunedRandomForest Validation Accuracy:  0.5322180916976456\n",
      "TunedRandomForest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           A       0.45      0.44      0.45       391\n",
      "           B       0.43      0.33      0.37       369\n",
      "           C       0.52      0.57      0.54       380\n",
      "           D       0.65      0.74      0.69       474\n",
      "\n",
      "    accuracy                           0.53      1614\n",
      "   macro avg       0.51      0.52      0.51      1614\n",
      "weighted avg       0.52      0.53      0.52      1614\n",
      "\n",
      "GradientBoosting Validation Accuracy:  0.5285006195786865\n",
      "GradientBoosting Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           A       0.41      0.41      0.41       391\n",
      "           B       0.43      0.34      0.38       369\n",
      "           C       0.55      0.57      0.56       380\n",
      "           D       0.66      0.73      0.69       474\n",
      "\n",
      "    accuracy                           0.53      1614\n",
      "   macro avg       0.51      0.52      0.51      1614\n",
      "weighted avg       0.52      0.53      0.52      1614\n",
      "\n",
      "XGBoost Validation Accuracy:  0.5136307311028501\n",
      "XGBoost Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           A       0.41      0.40      0.40       391\n",
      "           B       0.41      0.36      0.38       369\n",
      "           C       0.53      0.57      0.55       380\n",
      "           D       0.64      0.69      0.66       474\n",
      "\n",
      "    accuracy                           0.51      1614\n",
      "   macro avg       0.50      0.50      0.50      1614\n",
      "weighted avg       0.51      0.51      0.51      1614\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# Encoding labels as numeric values\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train_split)\n",
    "y_val_encoded = label_encoder.transform(y_val_split)\n",
    "\n",
    "# Definining the models to compare\n",
    "models = {\n",
    "    'TunedRandomForest': best_rf,\n",
    "    'GradientBoosting': GradientBoostingClassifier(random_state=42),\n",
    "    'XGBoost': xgb.XGBClassifier(random_state=42)\n",
    "}\n",
    "\n",
    "# Training and evaluate each model\n",
    "for name, clf in models.items():\n",
    "    pipeline = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', clf)\n",
    "    ])\n",
    "    pipeline.fit(X_train_split, y_train_encoded if name == 'XGBoost' else y_train_split)\n",
    "    y_val_pred = pipeline.predict(X_val_split)\n",
    "    \n",
    "    # Decode predictions if using XGBoost\n",
    "    if name == 'XGBoost':\n",
    "        y_val_pred = label_encoder.inverse_transform(y_val_pred)\n",
    "    \n",
    "    print(f\"{name} Validation Accuracy: \", accuracy_score(y_val_split, y_val_pred))\n",
    "    print(f\"{name} Classification Report:\\n\", classification_report(y_val_split, y_val_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4c129d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "# Step 1: Identifying categorical columns\n",
    "categorical_features = ['Gender', 'Ever_Married', 'Graduated', 'Profession', 'Var_1']  # Update with your categorical columns\n",
    "numerical_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Step 2: Preprocessing Pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', SimpleImputer(strategy='mean'), numerical_features),  # Impute missing values for numerical features\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), categorical_features)  # One-hot encode categorical features\n",
    "    ])\n",
    "\n",
    "# Step 3: Transforming the data\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "# Step 4: Applying Polynomial Features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_poly = poly.fit_transform(X_train_preprocessed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1c4a1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
